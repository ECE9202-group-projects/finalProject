{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report,precision_recall_curve\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_dict = {\n",
    "  \"trafficlight\": 1,\n",
    "  \"stop\": 2,\n",
    "  \"speedlimit\": 3,\n",
    "  \"crosswalk\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to image and annotation directories\n",
    "images = \"/Users/favourokpali/Documents/Semester 2/ECE9022-Assignments/FinalProject/output_images/\"\n",
    "annotations = \"/Users/favourokpali/Documents/Semester 2/ECE9022-Assignments/FinalProject/annotations/\"\n",
    "\n",
    "# Initialize empty lists for image data and labels\n",
    "X_data = []\n",
    "Y_data = []\n",
    "\n",
    "\n",
    "# Set the desired image size (e.g., 256x256)\n",
    "image_size = (256, 256)\n",
    "\n",
    "# Iterate through images and annotations\n",
    "for image_name in os.listdir(images):\n",
    "    image_root_name = image_name.split('.')[0]\n",
    "    \n",
    "    for annotation_name in os.listdir(annotations):\n",
    "        annotation_root_name = annotation_name.split('.')[0]\n",
    "        \n",
    "        # Match image and annotation by root name\n",
    "        if annotation_root_name == image_root_name:\n",
    "            annotation_path = os.path.join(annotations, annotation_name)\n",
    "            tree = ET.parse(annotation_path)\n",
    "            root = tree.getroot()\n",
    "            num_objects = len(root.findall(\"object\"))\n",
    "\n",
    "            if num_objects == 1:\n",
    "\n",
    "                # Read and resize the image to a consistent shape (e.g., 256x256)\n",
    "                img_path = os.path.join(images, image_name)\n",
    "                try:\n",
    "                    img = mpimg.imread(img_path)\n",
    "                    img_resized = image.smart_resize(img, image_size)  # Resize image to 256x256\n",
    "                    img_resized = np.ravel(img_resized)  # Flatten image data\n",
    "                    X_data.append(img_resized)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading or resizing image {img_path}: {e}\")\n",
    "                    continue  # Skip this image if it fails to load or resize\n",
    "\n",
    "                # Parse annotation data (ensure proper indexing based on your XML structure)\n",
    "                y_value = root[4][0].text\n",
    "                \n",
    "                # Encode label based on the dictionary\n",
    "                try:\n",
    "                    annotation_encoded = sign_dict[str(y_value)]\n",
    "                    Y_data.append(annotation_encoded)\n",
    "                except KeyError:\n",
    "                    print(f\"Warning: Label {y_value} not found in sign_dict. Skipping.\")\n",
    "                    continue  # Skip this label if it is not found\n",
    "\n",
    "# Convert to DataFrames\n",
    "X_data = np.array(X_data)\n",
    "Y_data = np.array(Y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = X_data.reshape((X_data.shape[0], 512, 512, 1)) \n",
    "\n",
    "Y_data = Y_data.flatten()\n",
    "\n",
    "# Print unique values of Y_data to check the range\n",
    "Y_data_encoded = to_categorical(Y_data, num_classes=5)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_data, Y_data_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.6981 - loss: 42.9343 - val_accuracy: 0.7339 - val_loss: 7.3867\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4s/step - accuracy: 0.7519 - loss: 3.7243 - val_accuracy: 0.6774 - val_loss: 1.5723\n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4s/step - accuracy: 0.7616 - loss: 1.5942 - val_accuracy: 0.7500 - val_loss: 0.8412\n",
      "Epoch 4/10\n"
     ]
    }
   ],
   "source": [
    "# Build the CNN model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Add a convolutional layer with 32 filters, 3x3 kernel, and ReLU activation\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(512, 512, 1)))  # Adjust input shape as necessary\n",
    "\n",
    "# Add a max-pooling layer\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add another convolutional layer with 64 filters\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Add another max-pooling layer\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add a flatten layer to flatten the 2D matrix into 1D\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Add a fully connected (dense) layer with 128 neurons and ReLU activation\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "# Output layer with 4 neurons (one for each class) and softmax activation\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "# Compile the model with categorical cross-entropy loss, Adam optimizer, and accuracy metric\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_test, y_test))\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Accuracy vs. Loss Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 3. Confusion Matrix\n",
    "y_test_labels = np.argmax(y_test, axis=1)  # Convert one-hot to label format\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # If multi-class\n",
    "cm = confusion_matrix(y_test_labels, y_pred_classes)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test_labels), yticklabels=np.unique(y_test_labels))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# 4. Precision-Recall Curve\n",
    "plt.figure(figsize=(6, 6))\n",
    "for i in range(y_test.shape[1]):  # Loop through each class\n",
    "    precision, recall, _ = precision_recall_curve(y_test[:, i], y_pred[:, i])\n",
    "    plt.plot(recall, precision, label=f'Class {i}')\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
